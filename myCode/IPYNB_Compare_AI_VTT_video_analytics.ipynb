{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For python generation from a jupyter file, use following command:\n",
    "\n",
    "    `jupyter nbconvert --to script your_notebook.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    pipeline, AutoProcessor,\n",
    "    AutoModelForImageTextToText, AutoTokenizer, LlavaForConditionalGeneration,\n",
    "    LlavaNextVideoProcessor, LlavaNextVideoForConditionalGeneration,\n",
    ")\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import av\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "import sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"cuda available\" if torch.cuda.is_available() else \"cuda not available\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model ID and the local path where the model should be stored\n",
    "model_id = \"llava-hf/LLaVA-NeXT-Video-7B-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = os.path.expanduser(\"~/myProject_LLM/model/\")\n",
    "# Check if the model files exist in the local path\n",
    "model_files = [\"config.json\", \"pytorch_model.bin\"]\n",
    "model_exists = all(os.path.exists(os.path.join(local_model_path, file)) for file in model_files)\n",
    "print(f\"Model files exist: {model_exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LlavaNextVideoProcessor.from_pretrained(model_id, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the image you want to describe\n",
    "# Load the video as an np.array, sampling uniformly 8 frames (can sample more for longer videos)\n",
    "# video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"sample_demo_1.mp4\", repo_type=\"dataset\")\n",
    "video_path1 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-26-315.mp4\")\n",
    "video_path2 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-54-126.mp4\")\n",
    "video_path3 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-08-26-159.mp4\")\n",
    "image_path = os.path.expanduser(\"~/myProject_LLM/myDocs/picture.jpg\")\n",
    "file_path = video_path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\") \n",
    "conversation = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "          {\"type\": \"text\", \"text\": \"Beschreibe das Media auf Deutsch mit folgender Struktur: 1. Hauptmotiv, 2. Hintergrund, 3. Bewegungen, 4. Anzahl unterschiedliche Personen, 5. Ist es ein Einbruch?\"}\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "    \n",
    "# Supported extensions for images and videos\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n",
    "video_extensions = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
    "\n",
    "# Add files to the conversation\n",
    "\n",
    "ext = os.path.splitext(file_path)[1].lower()  # Get the file extension\n",
    "if ext in image_extensions:\n",
    "    conversation[0][\"content\"].append({\"type\": \"image\", \"path\": file_path})\n",
    "elif ext in video_extensions:\n",
    "    conversation[0][\"content\"].append({\"type\": \"video\", \"path\": file_path})\n",
    "else:\n",
    "    print(f\"Unsupported file type: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor.apply_chat_template(conversation, num_frames=8, add_generation_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the output\n",
    "decoded_output = processor.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "# Print the output in a readable format\n",
    "for line in decoded_output:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input FPS: 29.97002997002997\n",
      "Reduced FPS: 1\n",
      "Moviepy - Building video /home/gabriel/myProject_LLM/myDocs/RED1_BoschSmartCameras_11-04-2025_21-05-26-315.mp4.\n",
      "MoviePy - Writing audio in RED1_BoschSmartCameras_11-04-2025_21-05-26-315TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/gabriel/myProject_LLM/myDocs/RED1_BoschSmartCameras_11-04-2025_21-05-26-315.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/gabriel/myProject_LLM/myDocs/RED1_BoschSmartCameras_11-04-2025_21-05-26-315.mp4\n",
      "Output video saved to: /home/gabriel/myProject_LLM/myDocs/RED1_BoschSmartCameras_11-04-2025_21-05-26-315.mp4\n",
      "FPS : 29.97002997002997, 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def reduce_frames(input_video_path, output_video_path, target_fps, target_codec):\n",
    "    # Load the video file\n",
    "    video = VideoFileClip(input_video_path)\n",
    "    video_fps = video.fps\n",
    "    print(f\"Input FPS: {video_fps}\")\n",
    "    \n",
    "    try:\n",
    "        # Resample the video to the target FPS\n",
    "        video_reduced = video.set_fps(target_fps)\n",
    "        video_reduced_fps = video_reduced.fps\n",
    "        print(f\"Reduced FPS: {video_reduced_fps}\")\n",
    "        \n",
    "        # Write the output video file with the specified FPS\n",
    "        video_reduced.write_videofile(output_video_path, codec=target_codec, audio_codec=\"aac\", fps=target_fps)\n",
    "   \n",
    "\n",
    "        print(f\"Output video saved to: {output_video_path}\")\n",
    "    finally:\n",
    "        # Ensure resources are properly released\n",
    "        video.close()\n",
    "        video_reduced.close()\n",
    "    \n",
    "    return video_fps, video_reduced_fps\n",
    "\n",
    "# Example usage\n",
    "input_video_path1 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-26-315.mp4\")\n",
    "output_video_path1 = os.path.expanduser(\"~/myProject_LLM/myDocs/RED1_BoschSmartCameras_11-04-2025_21-05-26-315.mp4\")\n",
    "target_fps = 1\n",
    "target_codec=\"mpeg4\" \n",
    "\n",
    "in_fps, out_fps = reduce_frames(input_video_path1, output_video_path1, target_fps, target_codec)\n",
    "print(f\"FPS : {in_fps}, {out_fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant frame indices: [44, 61, 121, 181, 241, 298, 299, 300, 301, 337, 338, 339, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 365, 366, 367, 368, 369, 370, 374, 376, 378, 380, 384, 386, 387, 388, 389, 390, 391, 421, 481, 526, 528, 541, 601, 661, 721, 781, 841, 901, 961, 1021, 1081, 1141, 1201, 1261, 1321, 1381]\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_44.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_61.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_121.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_181.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_241.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_298.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_299.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_300.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_301.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_337.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_338.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_339.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_349.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_350.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_351.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_352.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_353.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_354.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_355.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_356.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_357.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_358.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_359.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_360.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_361.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_365.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_366.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_367.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_368.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_369.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_370.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_374.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_376.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_378.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_380.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_384.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_386.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_387.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_388.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_389.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_390.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_391.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_421.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_481.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_526.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_528.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_541.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_601.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_661.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_721.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_781.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_841.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_901.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_961.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1021.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1081.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1141.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1201.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1261.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1321.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_1381.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "\n",
    "video_path1 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-26-315.mp4\")\n",
    "video_path2 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-54-126.mp4\")\n",
    "video_path3 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-08-26-159.mp4\")\n",
    "\n",
    "input_video_path = video_path3\n",
    "output_frame_path = os.path.expanduser(\"~/myProject_LLM/myDocs/frames/\")\n",
    "\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "frame_diffs = []\n",
    "prev_frame = None\n",
    "relevant_frames = []\n",
    "frame_id = 0\n",
    "\n",
    "threshold = 30  # Sensitivity (tune this!)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    if prev_frame is not None:\n",
    "        diff = cv2.absdiff(gray, prev_frame)\n",
    "        non_zero_count = np.count_nonzero(diff)\n",
    "\n",
    "        if non_zero_count > threshold * gray.size / 100:\n",
    "            relevant_frames.append(frame_id)\n",
    "\n",
    "    prev_frame = gray\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"Relevant frame indices:\", frame_indices)\n",
    "\n",
    "# Videopfad und Ausgabeverzeichnis\n",
    "\n",
    "os.makedirs(output_frame_path, exist_ok=True)\n",
    "\n",
    "# Liste der relevanten Frames (zuvor ermittelt)\n",
    "\n",
    "# Video öffnen\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "frame_id = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id in relevant_frames:\n",
    "        filename = os.path.join(output_frame_path, f\"frame_{frame_id}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Gespeichert: {filename}\")\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante Frames (SSIM < 0.95): [275, 298, 299, 337, 356]\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_275.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_298.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_299.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_337.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_356.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "\n",
    "video_path1 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-26-315.mp4\")\n",
    "video_path2 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-05-54-126.mp4\")\n",
    "video_path3 = os.path.expanduser(\"~/myProject_LLM/myDocs/BoschSmartCameras_11-04-2025_21-08-26-159.mp4\")\n",
    "\n",
    "input_video_path = video_path3\n",
    "output_frame_path = os.path.expanduser(\"~/myProject_LLM/myDocs/frames/\")\n",
    "\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "frame_diffs = []\n",
    "prev_frame = None\n",
    "relevant_frames = []\n",
    "frame_id = 0\n",
    "ssim_threshold = 0.95  # < 1.0 means some change; lower = more sensitive\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    if prev_frame is not None:\n",
    "        # SSIM zwischen aktuellen und vorherigem Frame berechnen\n",
    "        score, _ = compare_ssim(prev_frame, gray, full=True)\n",
    "        \n",
    "        if score < ssim_threshold:\n",
    "            relevant_frames.append(frame_id)\n",
    "\n",
    "    prev_frame = gray\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"Relevante Frames (SSIM < {:.2f}):\".format(ssim_threshold), relevant_frames)\n",
    "\n",
    "\n",
    "# Videopfad und Ausgabeverzeichnis\n",
    "\n",
    "os.makedirs(output_frame_path, exist_ok=True)\n",
    "\n",
    "# Liste der relevanten Frames (zuvor ermittelt)\n",
    "\n",
    "# Video öffnen\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "frame_id = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id in relevant_frames:\n",
    "        filename = os.path.join(output_frame_path, f\"frame_{frame_id}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Gespeichert: {filename}\")\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_60.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_120.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_166.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_226.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_286.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_346.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_406.jpg\n",
      "Gespeichert: /home/gabriel/myProject_LLM/myDocs/frames/frame_466.jpg\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
